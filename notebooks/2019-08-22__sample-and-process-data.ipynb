{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode\n",
    "import swifter\n",
    "import spacy\n",
    "import util\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import nltk.corpus\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "print_sections = ['A', 'B', 'C', 'D', 'E', '1', '2', '3', '4']\n",
    "fnames = glob.glob('../nyt_corpus/csvs/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6a6acfe2ed42d09cf191f0a2b46e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (5,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "modeling_data = []\n",
    "testing_data = []\n",
    "\n",
    "for fname in tqdm(fnames):\n",
    "    year = int(os.path.basename(fname).replace('.csv', ''))  \n",
    "    article_df = pd.read_csv(fname, index_col=0)\n",
    "    \n",
    "    ## clean up \n",
    "    article_df = (article_df\n",
    "      .loc[lambda df: df[['publication_year', 'publication_month', 'publication_day_of_month']].notnull().any(axis=1)]\n",
    "    )\n",
    "\n",
    "    ## extra auxiliary columns\n",
    "    article_df['print_section_and_page'] = (article_df\n",
    "     .loc[lambda x: x['print_page_number'].notnull()]\n",
    "     .apply(lambda x: '%s-%03.f' % (x['print_section'] , int(x['print_page_number'])), axis=1)\n",
    "    )\n",
    "\n",
    "    article_df['pub_date'] = ((article_df\n",
    "        .apply(lambda x: datetime(\n",
    "            year, int(x['publication_month']), \n",
    "            int(x['publication_day_of_month'])\n",
    "        ), axis=1)\n",
    "    ))\n",
    "\n",
    "    ## add id column\n",
    "    article_df['id'] = article_df.apply(lambda x: uuid.uuid1(), axis=1)\n",
    "    \n",
    "    ## filter to weekdays and top sections\n",
    "    data_df = (article_df\n",
    "     .loc[lambda df: df['publication_day_of_week'].isin(weekdays[:-2])]\n",
    "     .loc[lambda df: df['print_section'].isin(print_sections[:-4])]\n",
    "    )\n",
    "\n",
    "    ## set index\n",
    "    pub_date_df = data_df.set_index('pub_date')\n",
    "\n",
    "    ## take sample\n",
    "    for day in pub_date_df.index.unique():\n",
    "        day_articles = pub_date_df.loc[day]\n",
    "\n",
    "        if len(day_articles.shape) > 1:\n",
    "            a_1 = (\n",
    "                day_articles\n",
    "                  .loc[lambda df: df['print_section_and_page'] == 'A-001']\n",
    "                  .loc[lambda df: df['body'].notnull()==True]\n",
    "                  .assign(label=1)\n",
    "            )\n",
    "\n",
    "            not_a_1 = (\n",
    "                day_articles\n",
    "                  .loc[lambda df: ~df['print_section_and_page'].isin(['A-001', 'A-002'])]\n",
    "                  .loc[lambda df: df['body'].notnull()==True]\n",
    "                  .sample(len(a_1) * 5)\n",
    "                  .assign(label=0)\n",
    "            )\n",
    "\n",
    "            modeling_data.append(a_1.reset_index())\n",
    "            modeling_data.append(not_a_1.reset_index())\n",
    "    \n",
    "    testing_data.append(pub_date_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "modeling_data_df = pd.concat(modeling_data)\n",
    "modeling_data_df = modeling_data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "testing_data_df = pd.concat(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data_df.to_csv(\"exploratory_analysis/unprocessed_sampled_data_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_df.to_csv(\"exploratory_analysis/unprocessed_full_data_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_balanced_train_df, time_balanced_test_df = (modeling_data_df\n",
    " .sort_values('pub_date')\n",
    " .pipe(lambda df: (df.iloc[:int(df.shape[0] * .75)], df.iloc[int(df.shape[0] * .75):]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_df = testing_data_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unbalanced_test_df = testing_data_df.loc[lambda df: df['pub_date'] > time_balanced_train_df['pub_date'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unbalanced_test_df.to_csv(\"exploratory_analysis/unprocessed_test_time_unbalanced_df.csv\")\n",
    "time_balanced_train_df.to_csv(\"exploratory_analysis/unprocessed_train_time_balanced_df.csv\")\n",
    "time_balanced_test_df.to_csv(\"exploratory_analysis/unprocessed_test_time_balanced_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_balanced_test_df = pd.read_csv(\"exploratory_analysis/unprocessed_test_time_balanced_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data_df = pd.read_csv(\"exploratory_analysis/unprocessed_sampled_data_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_num_regex = re.compile('\\s[a-f]\\d+(\\s|$)')\n",
    "specific_stop_words = [\n",
    "    'article',\n",
    "    'page',\n",
    "    'sportsmonday',\n",
    "    'sportstuesday',\n",
    "    'sportswednesday',\n",
    "    'sportsthursday',\n",
    "    'sportsfriday',\n",
    "    'sportssaturday',\n",
    "    'sportssunday',\n",
    "    'times',\n",
    "    'caption',\n",
    "    'science times',\n",
    "    'business day',\n",
    "    'editing error page',\n",
    "    'ap sports',\n",
    "    'ap',\n",
    "    'reuters',\n",
    "    'op ed contributor',\n",
    "    'books times',\n",
    "    'music review',\n",
    "    'op ed',\n",
    "    'sports times',\n",
    "    'articles , pages',\n",
    "    'articles pages',\n",
    "    'special today',\n",
    "    'science f1',\n",
    "    'art review',\n",
    "    'television review',\n",
    "    'articles series',\n",
    "    'ed contributor',\n",
    "    'news briefs',\n",
    "    'articles series',\n",
    "    'news analysis',\n",
    "    'sports people',\n",
    "    'company news',\n",
    "    'metro : new york',\n",
    "    'metro : new jersey',\n",
    "    'metro : new york city',\n",
    "    'metro : new york state',\n",
    "    'lead : editor',\n",
    "    'op - ed',\n",
    "    'company reports',\n",
    "    'dance review',\n",
    "    'theater review',\n",
    "    'public lives',\n",
    "    'world business , section w',\n",
    "    'world business briefing : europe',\n",
    "    'world business briefing : asia',\n",
    "    'world business briefings : middle east',\n",
    "    'world business briefing : africa',\n",
    "    'world business briefing : americas',\n",
    "    'world business briefings : europe',\n",
    "    'world business briefings : asia',\n",
    "    'world business briefing : world trade'\n",
    "]\n",
    "\n",
    "english_stopwords = [item.strip('\\n') for item in nltk.corpus.stopwords.open('english')]\n",
    "stopwords = specific_stop_words + english_stopwords\n",
    "\n",
    "def preprocess(body):\n",
    "    \"\"\"preprocess with spacy.\"\"\"\n",
    "    try:\n",
    "        ### spacy split\n",
    "        text = body.split()\n",
    "        text = ' '.join(text)\n",
    "        doc = nlp(text)\n",
    "        text = [word.text for word in doc]\n",
    "        body = ' '.join(text).replace('\\' \\'', '\"')\n",
    "\n",
    "        ### other cleanup\n",
    "        body = body.lower()\n",
    "        body = body.strip()\n",
    "        \n",
    "        ### replace stopwords\n",
    "        for stopword in stopwords:\n",
    "            ## stopword in body\n",
    "            body = body.replace(' ' + stopword + ' ', ' ')\n",
    "            ## stopword at start\n",
    "            if body[:len(stopword + ' ')] == (stopword + ' '):\n",
    "                body = body[len(stopword + ' '):]\n",
    "            ## stopword at end\n",
    "            if body[-len(' ' + stopword):] == (' ' + stopword):\n",
    "                body = body[:-len(' ' + stopword)]\n",
    "\n",
    "        ### replace page numbers\n",
    "        body = re.sub(page_num_regex, ' ', body)\n",
    "       \n",
    "        return unidecode.unidecode(body)\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "    \n",
    "def preprocess_lite(body):\n",
    "    \"\"\"preprocess without spacy.\"\"\"\n",
    "    body = body.strip()\n",
    "    \n",
    "    ### replace stopwords\n",
    "    for stopword in stopwords:\n",
    "        ## stopword in body\n",
    "        body = body.replace(' ' + stopword + ' ', ' ')\n",
    "        ## stopword at start\n",
    "        if body[:len(stopword + ' ')] == (stopword + ' '):\n",
    "            body = body[len(stopword + ' '):]\n",
    "        ## stopword at end\n",
    "        if body[-len(' ' + stopword):] == (' ' + stopword):\n",
    "            body = body[:-len(' ' + stopword)]\n",
    "        \n",
    "        \n",
    "    ### replace page numbers\n",
    "    body = re.sub(page_num_regex, ' ', body)\n",
    "        \n",
    "    return unidecode.unidecode(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa67a101d8b64c0eb41c1ec952300682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=91054), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_bodies = []\n",
    "\n",
    "for processed_body in tqdm(util.multiprocess(modeling_data_df['body'], preprocess), total=len(modeling_data_df)):\n",
    "    processed_bodies.append(processed_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d2e528dfee4eb4aa500f10524c55c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=91054, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modeling_data_df['processed_bodies'] = modeling_data_df['processed_bodies'].swifter.apply(preprocess_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data_df['processed_bodies'] = pd.Series(processed_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data_df.to_csv(\"exploratory_analysis/processed_sampled_data_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write for fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in modeling_data_df.apply(lambda x: '%s __label__%d' % (x['processed_bodies'], x['label']), axis=1):\n",
    "    lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write full dataset\n",
    "with open('exploratory_analysis/fasttext_processed_data.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_train, lines_test = train_test_split(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write training\n",
    "with open('exploratory_analysis/fasttext_processed_data_train.txt', 'w') as f:\n",
    "    for line in lines_train:\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "        \n",
    "## write test\n",
    "with open('exploratory_analysis/fasttext_processed_data_test.txt', 'w') as f:\n",
    "    for line in lines_test:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write time-stratified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "time_balanced_train_df = pd.read_csv(\"data/processed_train_time_balanced_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in time_balanced_train_df.apply(lambda x: '%s __label__%d' % (x['processed_bodies'], x['label']), axis=1):\n",
    "    lines.append(line)\n",
    "\n",
    "with open('data/fasttext_processed_data_train_balanced.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "time_unbalanced_test_df = pd.read_csv(\"data/processed_test_time_unbalanced_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for line in time_unbalanced_test_df.apply(lambda x: '%s __label__%d' % (x['processed_bodies'], x['label']), axis=1):\n",
    "    lines.append(line)\n",
    "\n",
    "with open('data/fasttext_processed_data_test_unbalanced.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess time splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fde5bd88de04f0eb0f849218568c26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=276882, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "time_unbalanced_test_df['processed_bodies'] = time_unbalanced_test_df['body'].swifter.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unbalanced_test_df = (\n",
    "    time_unbalanced_test_df\n",
    "    .loc[lambda df: df['body'].notnull()==True]\n",
    "    .loc[lambda df: df['print_section_and_page'] != 'A-002']\n",
    ")\n",
    "time_unbalanced_test_df['label'] = (\n",
    "    time_unbalanced_test_df\n",
    "    .apply(lambda x: 1 if (x['print_section_and_page'] == 'A-001') else 0, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_unbalanced_test_df.to_csv(\"exploratory_analysis/processed_test_time_unbalanced_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d168100164c24c9dba6e8120d7b06bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=68290, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_balanced_train_df['processed_bodies'] = time_balanced_train_df['body'].swifter.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_balanced_train_df.to_csv(\"exploratory_analysis/processed_train_time_balanced_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10f1016a58540f2bf42da1cd984f403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Pandas Apply', max=22764, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time_balanced_test_df['processed_bodies'] = time_balanced_test_df['body'].swifter.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_balanced_test_df.to_csv(\"exploratory_analysis/processed_test_time_balanced_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
